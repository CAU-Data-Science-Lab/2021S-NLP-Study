{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# koelectra 사용 (https://github.com/monologg/KoELECTRA)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data load / feature selection"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "일단, '요약문_연구목표', '요약문_연구내용', '요약문_기대효과' 를 사용해보기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import torch\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import datetime"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-08-03 11:43:29.058926: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# feather 파일 형식을 사용하기 위해 설치.\n",
    "!pip install pyarrow"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "train_data = pd.read_feather(\"./data/re_train_data.feather\")\n",
    "test_data = pd.read_feather(\"./data/re_test_data.feather\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "len(train_data), len(test_data)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(174304, 43576)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "remake dataset to fit on BERT / ELECTRA / etc..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "trainset / validset split"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## tokenizer / model settings"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from transformers import ElectraModel, ElectraTokenizer, ElectraForSequenceClassification\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v2-discriminator\")\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"\")\n",
    "\n",
    "\n",
    "# tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\", do_lower_case=False, add_special_tokens=True, max_length=512, pad_to_max_length=True, return_attention_mask=True, truncation=True)\n",
    "# model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# |[CLS] '요약문_연구목표' [SEP] |'요약문_연구내용' [SEP] | '요약문_기대효과' [SEP]|\n",
    "# |-----       64       -----|-----       128       -----|-----       64       -----|\n",
    "가 되도록."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def f1_tokenizer(sent, MAX_LEN):\n",
    "    encoded_dict=tokenizer.encode_plus(text = sent, add_special_tokens=True, max_length=MAX_LEN, pad_to_max_length=True, return_attention_mask=True, truncation = True)\n",
    "\t\n",
    "    input_id=encoded_dict['input_ids']\n",
    "    attention_mask=encoded_dict['attention_mask']\n",
    "    token_type_id = encoded_dict['token_type_ids']\n",
    "    \n",
    "    return input_id, attention_mask, token_type_id\n",
    "\n",
    "def f2_tokenizer(sent, MAX_LEN):\n",
    "    encoded_dict=tokenizer.encode_plus(text = sent, add_special_tokens=True, max_length=MAX_LEN+1, pad_to_max_length=True, return_attention_mask=True, truncation = True)\n",
    "\t\n",
    "    input_id=encoded_dict['input_ids'][1:]\n",
    "    attention_mask=encoded_dict['attention_mask'][1:]\n",
    "    token_type_id = encoded_dict['token_type_ids'][1:]\n",
    "    \n",
    "    return input_id, attention_mask, token_type_id"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "input_ids =[]\n",
    "attention_masks =[]\n",
    "token_type_ids =[]\n",
    "\n",
    "for train_obj in tqdm(train_data['요약문_연구목표']):\n",
    "    input_id1, attention_mask1, token_type_id1 = f1_tokenizer(train_obj, MAX_LEN=64)\n",
    "    \n",
    "    \n",
    "    input_ids.append(input_id1)\n",
    "    attention_masks.append(attention_mask1)\n",
    "    token_type_ids.append(token_type_id1)\n",
    "    \n",
    "for i, train_con in tqdm(enumerate(train_data['요약문_연구내용'])):\n",
    "    input_id2, attention_mask2, token_type_id2 = f2_tokenizer(train_con, MAX_LEN=128)\n",
    "    \n",
    "    input_ids[i].extend(input_id2)\n",
    "    attention_masks[i].extend(attention_mask2)\n",
    "    token_type_ids[i].extend(token_type_id2)\n",
    "\n",
    "for i, train_exp in tqdm(enumerate(train_data['요약문_기대효과'])):\n",
    "    input_id3, attention_mask3, token_type_id3 = f2_tokenizer(train_exp, MAX_LEN=64)\n",
    "    \n",
    "    input_ids[i].extend(input_id3)\n",
    "    attention_masks[i].extend(attention_mask3)\n",
    "    token_type_ids[i].extend(token_type_id3)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/174304 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "52355201e82340c9908f6a5476c48c5f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f152255ceea74a8285c4dcf811b55971"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4b49f517ff8240e99b390b697c48ba1f"
      }
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "test_input_ids =[]\n",
    "test_attention_masks =[]\n",
    "test_token_type_ids =[]\n",
    "\n",
    "for test_obj in tqdm(test_data['요약문_연구목표']):\n",
    "    input_id1, attention_mask1, token_type_id1 = f1_tokenizer(test_obj, MAX_LEN=64)\n",
    "    \n",
    "    \n",
    "    test_input_ids.append(input_id1)\n",
    "    test_attention_masks.append(attention_mask1)\n",
    "    test_token_type_ids.append(token_type_id1)\n",
    "\n",
    "    \n",
    "for i, test_con in tqdm(enumerate(test_data['요약문_연구내용'])):\n",
    "    input_id2, attention_mask2, token_type_id2 = f2_tokenizer(test_con, MAX_LEN=128)\n",
    "    \n",
    "    test_input_ids[i].extend(input_id2)\n",
    "    test_attention_masks[i].extend(attention_mask2)\n",
    "    test_token_type_ids[i].extend(token_type_id2)\n",
    "\n",
    "for i, test_exp in tqdm(enumerate(test_data['요약문_기대효과'])):\n",
    "    input_id3, attention_mask3, token_type_id3 = f2_tokenizer(test_exp, MAX_LEN=64)\n",
    "    \n",
    "    test_input_ids[i].extend(input_id3)\n",
    "    test_attention_masks[i].extend(attention_mask3)\n",
    "    test_token_type_ids[i].extend(token_type_id3)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/43576 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ce00637fe9a4424eb6dcfb07e4e90e3a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "035d4b76e618461a86ea7190e88d6f01"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7d781d7e23794f959fbbd7a748413fbf"
      }
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "train_inputs, valid_inputs, train_labels, valid_labels = train_test_split(input_ids, train_data['label'].values, random_state=42, test_size=0.1)\n",
    "train_masks, valid_masks, _, _ = train_test_split(attention_masks, input_ids, random_state=42, test_size=0.1)\n",
    "train_token_ids, valid_token_ids, _, _ = train_test_split(token_type_ids, input_ids, random_state=42, test_size=0.1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "train_inputs = torch.tensor(train_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "train_token_ids = torch.tensor(train_token_ids)\n",
    "valid_inputs = torch.tensor(valid_inputs)\n",
    "valid_labels = torch.tensor(valid_labels)\n",
    "valid_masks = torch.tensor(valid_masks)\n",
    "valid_token_ids = torch.tensor(valid_token_ids)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "trainset = TensorDataset(train_inputs, train_masks, train_token_ids, train_labels)\n",
    "train_sampler = RandomSampler(trainset)\n",
    "train_dataloader = DataLoader(trainset, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
    "\n",
    "validset = TensorDataset(valid_inputs, valid_masks, valid_token_ids, valid_labels)\n",
    "valid_sampler = SequentialSampler(validset)\n",
    "valid_dataloader = DataLoader(validset, sampler=valid_sampler, batch_size=BATCH_SIZE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "test_inputs = torch.tensor(test_input_ids)\n",
    "test_masks = torch.tensor(test_attention_masks)\n",
    "test_token_ids = torch.tensor(test_token_type_ids)\n",
    "\n",
    "testset = TensorDataset(test_inputs, test_masks, test_token_ids)\n",
    "test_sampler = SequentialSampler(testset)\n",
    "test_dataloader = DataLoader(testset, sampler=test_sampler, batch_size=BATCH_SIZE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "device = torch.device(\"cuda:6\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "model = ElectraForSequenceClassification.from_pretrained(\"monologg/koelectra-base-v2-discriminator\", num_labels=46)\n",
    "model.to(device)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at monologg/koelectra-base-v2-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v2-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(32200, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=46, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8) # 0으로 나누는 것을 방지하기 위한 epsilon 값\n",
    "epochs = 10\n",
    "# 총 훈련 스텝\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "# lr 조금씩 감소시키는 스케줄러\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# 정확도 계산 함수\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    #return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "    return fl_score(pred_flat, labels_flat, average='macro')\n",
    "    \n",
    "# 시간 표시 함수\n",
    "def format_time(elapsed):\n",
    "    # 반올림\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # hh:mm:ss으로 형태 변경\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# 재현을 위해 랜덤시드 고정\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# 그래디언트 초기화\n",
    "model.zero_grad()\n",
    "\n",
    "# 에폭만큼 반복\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # 시작 시간 설정\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 로스 초기화\n",
    "    total_loss = 0\n",
    "\n",
    "    # 훈련모드로 변경\n",
    "    model.train()\n",
    "        \n",
    "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # 경과 정보 표시\n",
    "        if step % 500 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # 배치를 GPU에 넣음\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # 배치에서 데이터 추출\n",
    "        b_input_ids, b_input_mask, b_token_ids, b_labels = batch\n",
    "\n",
    "        # Forward 수행                \n",
    "        outputs = model(b_input_ids, \n",
    "                        token_type_ids=b_token_ids, \n",
    "                        attention_mask=b_input_mask, \n",
    "                        labels=b_labels)\n",
    "        \n",
    "        # 로스 구함\n",
    "        loss = outputs[0]\n",
    "\n",
    "        # 총 로스 계산\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Backward 수행으로 그래디언트 계산\n",
    "        loss.backward()\n",
    "\n",
    "        # 그래디언트 클리핑\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # 그래디언트를 통해 가중치 파라미터 업데이트\n",
    "        optimizer.step()\n",
    "\n",
    "        # 스케줄러로 학습률 감소\n",
    "        scheduler.step()\n",
    "\n",
    "        # 그래디언트 초기화\n",
    "        model.zero_grad()\n",
    "\n",
    "    # 평균 로스 계산\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    #시작 시간 설정\n",
    "    t0 = time.time()\n",
    "\n",
    "    # 평가모드로 변경\n",
    "    model.eval()\n",
    "\n",
    "    # 변수 초기화\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "\n",
    "    # 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "    for batch in valid_dataloader:\n",
    "        # 배치를 GPU에 넣음\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        \n",
    "        # 배치에서 데이터 추출\n",
    "        b_input_ids, b_input_mask, b_token_ids, b_labels = batch\n",
    "        \n",
    "        # 그래디언트 계산 안함\n",
    "        with torch.no_grad():     \n",
    "            # Forward 수행\n",
    "            outputs = model(b_input_ids, \n",
    "                            token_type_ids=b_token_ids, \n",
    "                            attention_mask=b_input_mask)\n",
    "        \n",
    "        # 로스 구함\n",
    "        logits = outputs[0]\n",
    "\n",
    "        # CPU로 데이터 이동\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # 출력 로짓과 라벨을 비교하여 정확도 계산\n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        nb_eval_steps += 1\n",
    "        \n",
    "    avg_valid_loss = logits / len(valid_dataloader)            \n",
    "\n",
    "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
    "    print(\"  Average validation loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "    \n",
    "    if not best_val_loss or avg_valid_loss < best_val_loss:\n",
    "\t    if not os.path.isdir(\"model_weights\"):\n",
    "            os.makedirs(\"model_weights\")\n",
    "        best_epoch = e\n",
    "        torch.save(model.state_dict(), './model_weights/koelectra_model_{}.pt'.format(e))\n",
    "        best_val_loss = val_epoch_loss\n",
    "\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "======== Epoch 1 / 10 ========\n",
      "Training...\n",
      "  Batch   500  of  9,805.    Elapsed: 0:08:32.\n",
      "  Batch 1,000  of  9,805.    Elapsed: 0:23:58.\n",
      "  Batch 1,500  of  9,805.    Elapsed: 0:39:24.\n",
      "  Batch 2,000  of  9,805.    Elapsed: 0:54:50.\n",
      "  Batch 2,500  of  9,805.    Elapsed: 1:10:16.\n",
      "  Batch 3,000  of  9,805.    Elapsed: 1:25:43.\n",
      "  Batch 3,500  of  9,805.    Elapsed: 1:41:09.\n",
      "  Batch 4,000  of  9,805.    Elapsed: 1:56:35.\n",
      "  Batch 4,500  of  9,805.    Elapsed: 2:12:00.\n",
      "  Batch 5,000  of  9,805.    Elapsed: 2:27:26.\n",
      "  Batch 5,500  of  9,805.    Elapsed: 2:42:52.\n",
      "  Batch 6,000  of  9,805.    Elapsed: 2:58:17.\n",
      "  Batch 6,500  of  9,805.    Elapsed: 3:13:43.\n",
      "  Batch 7,000  of  9,805.    Elapsed: 3:29:09.\n",
      "  Batch 7,500  of  9,805.    Elapsed: 3:44:34.\n",
      "  Batch 8,000  of  9,805.    Elapsed: 4:00:00.\n",
      "  Batch 8,500  of  9,805.    Elapsed: 4:15:25.\n",
      "  Batch 9,000  of  9,805.    Elapsed: 4:30:51.\n",
      "  Batch 9,500  of  9,805.    Elapsed: 4:46:16.\n",
      "\n",
      "  Average training loss: 0.65\n",
      "  Training epcoh took: 4:55:40\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.85\n",
      "  Validation took: 0:11:35\n",
      "\n",
      "======== Epoch 2 / 10 ========\n",
      "Training...\n",
      "  Batch   500  of  9,805.    Elapsed: 0:15:25.\n",
      "  Batch 1,000  of  9,805.    Elapsed: 0:30:50.\n",
      "  Batch 1,500  of  9,805.    Elapsed: 0:46:16.\n",
      "  Batch 2,000  of  9,805.    Elapsed: 1:01:42.\n",
      "  Batch 2,500  of  9,805.    Elapsed: 1:17:07.\n",
      "  Batch 3,000  of  9,805.    Elapsed: 1:32:33.\n",
      "  Batch 3,500  of  9,805.    Elapsed: 1:47:58.\n",
      "  Batch 4,000  of  9,805.    Elapsed: 2:03:23.\n",
      "  Batch 4,500  of  9,805.    Elapsed: 2:18:48.\n",
      "  Batch 5,000  of  9,805.    Elapsed: 2:34:13.\n",
      "  Batch 5,500  of  9,805.    Elapsed: 2:49:38.\n",
      "  Batch 6,000  of  9,805.    Elapsed: 3:05:04.\n",
      "  Batch 6,500  of  9,805.    Elapsed: 3:20:29.\n",
      "  Batch 7,000  of  9,805.    Elapsed: 3:35:54.\n",
      "  Batch 7,500  of  9,805.    Elapsed: 3:51:19.\n",
      "  Batch 8,000  of  9,805.    Elapsed: 4:06:44.\n",
      "  Batch 8,500  of  9,805.    Elapsed: 4:22:09.\n",
      "  Batch 9,000  of  9,805.    Elapsed: 4:37:35.\n",
      "  Batch 9,500  of  9,805.    Elapsed: 4:53:00.\n",
      "\n",
      "  Average training loss: 0.42\n",
      "  Training epcoh took: 5:02:24\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.88\n",
      "  Validation took: 0:11:35\n",
      "\n",
      "======== Epoch 3 / 10 ========\n",
      "Training...\n",
      "  Batch   500  of  9,805.    Elapsed: 0:15:25.\n",
      "  Batch 1,000  of  9,805.    Elapsed: 0:30:50.\n",
      "  Batch 1,500  of  9,805.    Elapsed: 0:46:15.\n",
      "  Batch 2,000  of  9,805.    Elapsed: 1:01:40.\n",
      "  Batch 2,500  of  9,805.    Elapsed: 1:17:05.\n",
      "  Batch 3,000  of  9,805.    Elapsed: 1:32:30.\n",
      "  Batch 3,500  of  9,805.    Elapsed: 1:47:56.\n",
      "  Batch 4,000  of  9,805.    Elapsed: 2:03:21.\n",
      "  Batch 4,500  of  9,805.    Elapsed: 2:18:46.\n",
      "  Batch 5,000  of  9,805.    Elapsed: 2:34:12.\n",
      "  Batch 5,500  of  9,805.    Elapsed: 2:49:38.\n",
      "  Batch 6,000  of  9,805.    Elapsed: 3:05:04.\n",
      "  Batch 6,500  of  9,805.    Elapsed: 3:20:29.\n",
      "  Batch 7,000  of  9,805.    Elapsed: 3:35:55.\n",
      "  Batch 7,500  of  9,805.    Elapsed: 3:51:20.\n",
      "  Batch 8,000  of  9,805.    Elapsed: 4:06:46.\n",
      "  Batch 8,500  of  9,805.    Elapsed: 4:22:11.\n",
      "  Batch 9,000  of  9,805.    Elapsed: 4:37:37.\n",
      "  Batch 9,500  of  9,805.    Elapsed: 4:53:02.\n",
      "\n",
      "  Average training loss: 0.33\n",
      "  Training epcoh took: 5:02:26\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.90\n",
      "  Validation took: 0:11:35\n",
      "\n",
      "======== Epoch 4 / 10 ========\n",
      "Training...\n",
      "  Batch   500  of  9,805.    Elapsed: 0:15:25.\n",
      "  Batch 1,000  of  9,805.    Elapsed: 0:30:51.\n",
      "  Batch 1,500  of  9,805.    Elapsed: 0:46:16.\n",
      "  Batch 2,000  of  9,805.    Elapsed: 1:01:41.\n",
      "  Batch 2,500  of  9,805.    Elapsed: 1:17:06.\n",
      "  Batch 3,000  of  9,805.    Elapsed: 1:32:31.\n",
      "  Batch 3,500  of  9,805.    Elapsed: 1:47:57.\n",
      "  Batch 4,000  of  9,805.    Elapsed: 2:03:22.\n",
      "  Batch 4,500  of  9,805.    Elapsed: 2:18:48.\n",
      "  Batch 5,000  of  9,805.    Elapsed: 2:34:14.\n",
      "  Batch 5,500  of  9,805.    Elapsed: 2:49:39.\n",
      "  Batch 6,000  of  9,805.    Elapsed: 3:05:04.\n",
      "  Batch 6,500  of  9,805.    Elapsed: 3:20:30.\n",
      "  Batch 7,000  of  9,805.    Elapsed: 3:35:55.\n",
      "  Batch 7,500  of  9,805.    Elapsed: 3:51:20.\n",
      "  Batch 8,000  of  9,805.    Elapsed: 4:06:45.\n",
      "  Batch 8,500  of  9,805.    Elapsed: 4:22:10.\n",
      "  Batch 9,000  of  9,805.    Elapsed: 4:37:35.\n",
      "  Batch 9,500  of  9,805.    Elapsed: 4:53:01.\n",
      "\n",
      "  Average training loss: 0.26\n",
      "  Training epcoh took: 5:02:25\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.90\n",
      "  Validation took: 0:11:35\n",
      "\n",
      "======== Epoch 5 / 10 ========\n",
      "Training...\n",
      "  Batch   500  of  9,805.    Elapsed: 0:15:26.\n",
      "  Batch 1,000  of  9,805.    Elapsed: 0:30:51.\n",
      "  Batch 1,500  of  9,805.    Elapsed: 0:46:17.\n",
      "  Batch 2,000  of  9,805.    Elapsed: 1:01:42.\n",
      "  Batch 2,500  of  9,805.    Elapsed: 1:17:08.\n",
      "  Batch 3,000  of  9,805.    Elapsed: 1:32:34.\n",
      "  Batch 3,500  of  9,805.    Elapsed: 1:48:00.\n",
      "  Batch 4,000  of  9,805.    Elapsed: 2:03:26.\n",
      "  Batch 4,500  of  9,805.    Elapsed: 2:18:52.\n",
      "  Batch 5,000  of  9,805.    Elapsed: 2:34:18.\n",
      "  Batch 5,500  of  9,805.    Elapsed: 2:49:45.\n",
      "  Batch 6,000  of  9,805.    Elapsed: 3:05:11.\n",
      "  Batch 6,500  of  9,805.    Elapsed: 3:20:37.\n",
      "  Batch 7,000  of  9,805.    Elapsed: 3:36:03.\n",
      "  Batch 7,500  of  9,805.    Elapsed: 3:51:29.\n",
      "  Batch 8,000  of  9,805.    Elapsed: 4:06:55.\n",
      "  Batch 8,500  of  9,805.    Elapsed: 4:22:21.\n",
      "  Batch 9,000  of  9,805.    Elapsed: 4:37:47.\n",
      "  Batch 9,500  of  9,805.    Elapsed: 4:53:14.\n",
      "\n",
      "  Average training loss: 0.21\n",
      "  Training epcoh took: 5:02:39\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.91\n",
      "  Validation took: 0:11:36\n",
      "\n",
      "======== Epoch 6 / 10 ========\n",
      "Training...\n",
      "  Batch   500  of  9,805.    Elapsed: 0:15:27.\n",
      "  Batch 1,000  of  9,805.    Elapsed: 0:30:54.\n",
      "  Batch 1,500  of  9,805.    Elapsed: 0:46:20.\n",
      "  Batch 2,000  of  9,805.    Elapsed: 1:01:46.\n",
      "  Batch 2,500  of  9,805.    Elapsed: 1:17:13.\n",
      "  Batch 3,000  of  9,805.    Elapsed: 1:32:39.\n",
      "  Batch 3,500  of  9,805.    Elapsed: 1:48:05.\n",
      "  Batch 4,000  of  9,805.    Elapsed: 2:03:32.\n",
      "  Batch 4,500  of  9,805.    Elapsed: 2:18:58.\n",
      "  Batch 5,000  of  9,805.    Elapsed: 2:34:25.\n",
      "  Batch 5,500  of  9,805.    Elapsed: 2:49:51.\n",
      "  Batch 6,000  of  9,805.    Elapsed: 3:05:18.\n",
      "  Batch 6,500  of  9,805.    Elapsed: 3:20:45.\n",
      "  Batch 7,000  of  9,805.    Elapsed: 3:36:12.\n",
      "  Batch 7,500  of  9,805.    Elapsed: 3:51:40.\n",
      "  Batch 8,000  of  9,805.    Elapsed: 4:07:07.\n",
      "  Batch 8,500  of  9,805.    Elapsed: 4:22:34.\n",
      "  Batch 9,000  of  9,805.    Elapsed: 4:38:00.\n",
      "  Batch 9,500  of  9,805.    Elapsed: 4:53:27.\n",
      "\n",
      "  Average training loss: 0.17\n",
      "  Training epcoh took: 5:02:51\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.91\n",
      "  Validation took: 0:11:36\n",
      "\n",
      "======== Epoch 7 / 10 ========\n",
      "Training...\n",
      "  Batch   500  of  9,805.    Elapsed: 0:15:27.\n",
      "  Batch 1,000  of  9,805.    Elapsed: 0:30:53.\n",
      "  Batch 1,500  of  9,805.    Elapsed: 0:46:20.\n",
      "  Batch 2,000  of  9,805.    Elapsed: 1:01:46.\n",
      "  Batch 2,500  of  9,805.    Elapsed: 1:17:12.\n",
      "  Batch 3,000  of  9,805.    Elapsed: 1:32:38.\n",
      "  Batch 3,500  of  9,805.    Elapsed: 1:48:04.\n",
      "  Batch 4,000  of  9,805.    Elapsed: 2:03:30.\n",
      "  Batch 4,500  of  9,805.    Elapsed: 2:18:56.\n",
      "  Batch 5,000  of  9,805.    Elapsed: 2:34:22.\n",
      "  Batch 5,500  of  9,805.    Elapsed: 2:49:47.\n",
      "  Batch 6,000  of  9,805.    Elapsed: 3:05:13.\n",
      "  Batch 6,500  of  9,805.    Elapsed: 3:20:38.\n",
      "  Batch 7,000  of  9,805.    Elapsed: 3:36:04.\n",
      "  Batch 7,500  of  9,805.    Elapsed: 3:51:30.\n",
      "  Batch 8,000  of  9,805.    Elapsed: 4:06:57.\n",
      "  Batch 8,500  of  9,805.    Elapsed: 4:22:23.\n",
      "  Batch 9,000  of  9,805.    Elapsed: 4:37:49.\n",
      "  Batch 9,500  of  9,805.    Elapsed: 4:53:14.\n",
      "\n",
      "  Average training loss: 0.13\n",
      "  Training epcoh took: 5:02:39\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.92\n",
      "  Validation took: 0:11:36\n",
      "\n",
      "======== Epoch 8 / 10 ========\n",
      "Training...\n",
      "  Batch   500  of  9,805.    Elapsed: 0:15:26.\n",
      "  Batch 1,000  of  9,805.    Elapsed: 0:30:50.\n",
      "  Batch 1,500  of  9,805.    Elapsed: 0:46:15.\n",
      "  Batch 2,000  of  9,805.    Elapsed: 1:01:38.\n",
      "  Batch 2,500  of  9,805.    Elapsed: 1:17:01.\n",
      "  Batch 3,000  of  9,805.    Elapsed: 1:32:25.\n",
      "  Batch 3,500  of  9,805.    Elapsed: 1:47:47.\n",
      "  Batch 4,000  of  9,805.    Elapsed: 2:03:09.\n",
      "  Batch 4,500  of  9,805.    Elapsed: 2:18:32.\n",
      "  Batch 5,000  of  9,805.    Elapsed: 2:33:54.\n",
      "  Batch 5,500  of  9,805.    Elapsed: 2:49:17.\n",
      "  Batch 6,000  of  9,805.    Elapsed: 3:04:39.\n",
      "  Batch 6,500  of  9,805.    Elapsed: 3:20:01.\n",
      "  Batch 7,000  of  9,805.    Elapsed: 3:35:24.\n",
      "  Batch 7,500  of  9,805.    Elapsed: 3:50:48.\n",
      "  Batch 8,000  of  9,805.    Elapsed: 4:06:13.\n",
      "  Batch 8,500  of  9,805.    Elapsed: 4:21:38.\n",
      "  Batch 9,000  of  9,805.    Elapsed: 4:37:00.\n",
      "  Batch 9,500  of  9,805.    Elapsed: 4:52:24.\n",
      "\n",
      "  Average training loss: 0.11\n",
      "  Training epcoh took: 5:01:46\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.92\n",
      "  Validation took: 0:11:34\n",
      "\n",
      "======== Epoch 9 / 10 ========\n",
      "Training...\n",
      "  Batch   500  of  9,805.    Elapsed: 0:15:24.\n",
      "  Batch 1,000  of  9,805.    Elapsed: 0:30:49.\n",
      "  Batch 1,500  of  9,805.    Elapsed: 0:46:13.\n",
      "  Batch 2,000  of  9,805.    Elapsed: 1:01:37.\n",
      "  Batch 2,500  of  9,805.    Elapsed: 1:17:01.\n",
      "  Batch 3,000  of  9,805.    Elapsed: 1:32:25.\n",
      "  Batch 3,500  of  9,805.    Elapsed: 1:47:49.\n",
      "  Batch 4,000  of  9,805.    Elapsed: 2:03:13.\n",
      "  Batch 4,500  of  9,805.    Elapsed: 2:18:37.\n",
      "  Batch 5,000  of  9,805.    Elapsed: 2:34:01.\n",
      "  Batch 5,500  of  9,805.    Elapsed: 2:49:23.\n",
      "  Batch 6,000  of  9,805.    Elapsed: 3:04:45.\n",
      "  Batch 6,500  of  9,805.    Elapsed: 3:20:09.\n",
      "  Batch 7,000  of  9,805.    Elapsed: 3:35:33.\n",
      "  Batch 7,500  of  9,805.    Elapsed: 3:50:57.\n",
      "  Batch 8,000  of  9,805.    Elapsed: 4:06:21.\n",
      "  Batch 8,500  of  9,805.    Elapsed: 4:21:45.\n",
      "  Batch 9,000  of  9,805.    Elapsed: 4:37:10.\n",
      "  Batch 9,500  of  9,805.    Elapsed: 4:52:34.\n",
      "\n",
      "  Average training loss: 0.09\n",
      "  Training epcoh took: 5:01:57\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.92\n",
      "  Validation took: 0:11:34\n",
      "\n",
      "======== Epoch 10 / 10 ========\n",
      "Training...\n",
      "  Batch   500  of  9,805.    Elapsed: 0:15:24.\n",
      "  Batch 1,000  of  9,805.    Elapsed: 0:30:48.\n",
      "  Batch 1,500  of  9,805.    Elapsed: 0:46:13.\n",
      "  Batch 2,000  of  9,805.    Elapsed: 1:01:37.\n",
      "  Batch 2,500  of  9,805.    Elapsed: 1:17:01.\n",
      "  Batch 3,000  of  9,805.    Elapsed: 1:32:25.\n",
      "  Batch 3,500  of  9,805.    Elapsed: 1:47:49.\n",
      "  Batch 4,000  of  9,805.    Elapsed: 2:03:13.\n",
      "  Batch 4,500  of  9,805.    Elapsed: 2:18:38.\n",
      "  Batch 5,000  of  9,805.    Elapsed: 2:34:02.\n",
      "  Batch 5,500  of  9,805.    Elapsed: 2:49:26.\n",
      "  Batch 6,000  of  9,805.    Elapsed: 3:04:50.\n",
      "  Batch 6,500  of  9,805.    Elapsed: 3:20:14.\n",
      "  Batch 7,000  of  9,805.    Elapsed: 3:35:39.\n",
      "  Batch 7,500  of  9,805.    Elapsed: 3:51:03.\n",
      "  Batch 8,000  of  9,805.    Elapsed: 4:06:27.\n",
      "  Batch 8,500  of  9,805.    Elapsed: 4:21:51.\n",
      "  Batch 9,000  of  9,805.    Elapsed: 4:37:15.\n",
      "  Batch 9,500  of  9,805.    Elapsed: 4:52:39.\n",
      "\n",
      "  Average training loss: 0.07\n",
      "  Training epcoh took: 5:02:02\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.92\n",
      "  Validation took: 0:11:34\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "len(outputs[0])   # batch_size만큼, 마지막 batch라 16이 아니라, 남은 숫자만큼 나옴."
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "len(outputs[0][0]) # 확률 값"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "outputs[0][0]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([ 10.3797,  -5.5306,  -7.1882, -10.0134, -15.0338,  -3.8773, -10.6498,\n",
       "        -13.2892,  -8.1916, -11.3695,  -7.0370,  -8.0767,  -8.1087,  -5.4747,\n",
       "         -4.1041, -11.1189,  -4.5186,  -7.5130,  -4.2910,  -0.9708,  -3.3784,\n",
       "         -8.4583, -10.3509,  -5.5739,  -5.1307,  -6.1944,  -8.6184,  -8.1003,\n",
       "         -6.4558,  -4.8816, -12.8358,  -7.0732,  -8.9400,  -6.6901,  -6.9372,\n",
       "         -8.2235,  -5.1464,  -8.5271,  -9.4629, -16.7443,  -8.2850,  -8.1729,\n",
       "         -5.5341,  -8.9708, -12.2611,  -2.7458], device='cuda:6')"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "#시작 시간 설정\n",
    "t0 = time.time()\n",
    "\n",
    "# 평가모드로 변경\n",
    "model.load_state_dict(torch.load('./model_weights/koelectra_model_{}.pt'.format(best_epoch)))\n",
    "model.eval()\n",
    "\n",
    "# 변수 초기화\n",
    "nb_eval_steps, nb_eval_examples = 0, 0\n",
    "y_pred_list = []\n",
    "\n",
    "# 데이터로더에서 배치만큼 반복하여 가져옴\n",
    "for step, batch in enumerate(test_dataloader):\n",
    "    # 경과 정보 표시\n",
    "    if step % 300 == 0 and not step == 0:\n",
    "        elapsed = format_time(time.time() - t0)\n",
    "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\n",
    "\n",
    "    # 배치를 GPU에 넣음\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # 배치에서 데이터 추출\n",
    "    b_input_ids, b_input_mask, b_token_ids = batch\n",
    "    \n",
    "    # 그래디언트 계산 안함\n",
    "    with torch.no_grad():     \n",
    "        # Forward 수행\n",
    "        outputs = model(b_input_ids, token_type_ids=b_token_ids, attention_mask=b_input_mask)\n",
    "    \n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    \n",
    "    y_pred_list.append(np.argmax(logits, axis=1).flatten())\n",
    "\n",
    "\n",
    "print(\"\")\n",
    "print(\"Test took: {:}\".format(format_time(time.time() - t0)))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  Batch   100  of  2,724.    Elapsed: 0:00:09.\n",
      "  Batch   200  of  2,724.    Elapsed: 0:00:18.\n",
      "  Batch   300  of  2,724.    Elapsed: 0:00:27.\n",
      "  Batch   400  of  2,724.    Elapsed: 0:00:37.\n",
      "  Batch   500  of  2,724.    Elapsed: 0:00:46.\n",
      "  Batch   600  of  2,724.    Elapsed: 0:00:56.\n",
      "  Batch   700  of  2,724.    Elapsed: 0:01:13.\n",
      "  Batch   800  of  2,724.    Elapsed: 0:02:04.\n",
      "  Batch   900  of  2,724.    Elapsed: 0:03:08.\n",
      "  Batch 1,000  of  2,724.    Elapsed: 0:04:11.\n",
      "  Batch 1,100  of  2,724.    Elapsed: 0:05:15.\n",
      "  Batch 1,200  of  2,724.    Elapsed: 0:06:19.\n",
      "  Batch 1,300  of  2,724.    Elapsed: 0:07:22.\n",
      "  Batch 1,400  of  2,724.    Elapsed: 0:08:26.\n",
      "  Batch 1,500  of  2,724.    Elapsed: 0:09:30.\n",
      "  Batch 1,600  of  2,724.    Elapsed: 0:10:33.\n",
      "  Batch 1,700  of  2,724.    Elapsed: 0:11:37.\n",
      "  Batch 1,800  of  2,724.    Elapsed: 0:12:41.\n",
      "  Batch 1,900  of  2,724.    Elapsed: 0:13:44.\n",
      "  Batch 2,000  of  2,724.    Elapsed: 0:14:48.\n",
      "  Batch 2,100  of  2,724.    Elapsed: 0:15:51.\n",
      "  Batch 2,200  of  2,724.    Elapsed: 0:16:55.\n",
      "  Batch 2,300  of  2,724.    Elapsed: 0:17:59.\n",
      "  Batch 2,400  of  2,724.    Elapsed: 0:19:02.\n",
      "  Batch 2,500  of  2,724.    Elapsed: 0:20:06.\n",
      "  Batch 2,600  of  2,724.    Elapsed: 0:21:09.\n",
      "  Batch 2,700  of  2,724.    Elapsed: 0:22:13.\n",
      "\n",
      "Test took: 0:22:28\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "y_pred_list[:10]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[array([ 0,  0,  0, 19,  0,  0, 18,  0,  0, 14,  0,  0, 23,  0,  0,  0]),\n",
       " array([ 0,  0,  0,  0, 27,  0,  0,  0, 24,  0,  0, 20,  0,  0,  0,  0]),\n",
       " array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 29,  0,  0,  0,  0,  0]),\n",
       " array([ 0, 29,  0,  0,  1,  0,  5, 14,  0,  0,  0,  0,  0,  0, 43, 19]),\n",
       " array([ 0,  0,  0,  0, 23,  0,  0,  0,  0,  0,  0,  0,  0,  0, 19,  0]),\n",
       " array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 25, 18,  0,  0,  0,  0]),\n",
       " array([ 0,  0,  0,  0,  0,  0,  0,  0, 43,  0,  0,  0,  0,  0,  0, 31]),\n",
       " array([ 0,  0,  0,  0,  0,  0,  0,  0,  0, 45,  0,  0,  0,  0,  0,  0]),\n",
       " array([ 0,  0,  0,  0,  0,  0,  0, 14, 27,  0,  0,  0,  0,  0,  0,  0]),\n",
       " array([ 0,  0,  0,  0,  0,  0,  0,  0, 23,  0,  0,  0,  0,  0,  0,  0])]"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "len(np.concatenate(y_pred_list))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "43576"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "source": [
    "pred_result = np.concatenate(y_pred_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "len(test_data), len(pred_result)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(43576, 43576)"
      ]
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "source": [
    "submission = pd.read_csv('./data/sample_submission.csv')\n",
    "submission['label']= pred_result"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "source": [
    "submission.label.value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0     36568\n",
       "19      978\n",
       "24      737\n",
       "14      436\n",
       "5       417\n",
       "23      386\n",
       "18      325\n",
       "1       281\n",
       "29      250\n",
       "45      244\n",
       "36      243\n",
       "31      221\n",
       "20      206\n",
       "13      169\n",
       "25      168\n",
       "27      159\n",
       "10      145\n",
       "16      133\n",
       "21      132\n",
       "34      123\n",
       "40      116\n",
       "28      108\n",
       "33      104\n",
       "8        77\n",
       "43       73\n",
       "38       68\n",
       "2        67\n",
       "12       61\n",
       "30       60\n",
       "35       59\n",
       "37       54\n",
       "32       52\n",
       "26       50\n",
       "11       44\n",
       "22       37\n",
       "7        35\n",
       "15       32\n",
       "39       31\n",
       "9        29\n",
       "3        27\n",
       "44       23\n",
       "6        16\n",
       "17       16\n",
       "4        11\n",
       "42        5\n",
       "Name: label, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "source": [
    "submission.to_csv(\"./data/koelectra_256_10epochs.csv\", index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "source": [
    "pd.read_csv(\"./data/koelectra_256_10epochs.csv\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        index  label\n",
       "0      174304      0\n",
       "1      174305      0\n",
       "2      174306      0\n",
       "3      174307     19\n",
       "4      174308      0\n",
       "...       ...    ...\n",
       "43571  217875      0\n",
       "43572  217876      0\n",
       "43573  217877      2\n",
       "43574  217878      0\n",
       "43575  217879      0\n",
       "\n",
       "[43576 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>174304</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>174305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>174306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>174307</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>174308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43571</th>\n",
       "      <td>217875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43572</th>\n",
       "      <td>217876</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43573</th>\n",
       "      <td>217877</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43574</th>\n",
       "      <td>217878</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43575</th>\n",
       "      <td>217879</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43576 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('kobert': conda)"
  },
  "interpreter": {
   "hash": "2edddfc9d5bed511733511e71708c2823425ae529162a5f8877df66aaf5564aa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}