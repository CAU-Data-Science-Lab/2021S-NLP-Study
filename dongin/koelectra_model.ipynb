{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# koelectra 사용 (https://github.com/monologg/KoELECTRA)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data load / feature selection"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "일단, '요약문_연구목표', '요약문_연구내용', '요약문_기대효과' 를 사용해보기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.optim as optim\r\n",
    "from torch.utils.data import DataLoader, TensorDataset\r\n",
    "\r\n",
    "\r\n",
    "from transformers import AdamW\r\n",
    "from transformers import get_linear_schedule_with_warmup\r\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import random\r\n",
    "import time\r\n",
    "import datetime\r\n",
    "\r\n",
    "from tqdm.notebook import tqdm"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-08-03 11:43:29.058926: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "train_data = pd.read_csv(\"./data/re_train_data.csv\")\r\n",
    "test_data = pd.read_csv(\"./data/re_test_data.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "len(train_data), len(test_data)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(174304, 43576)"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "trainset / validset split"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## tokenizer / model settings"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "from transformers import ElectraTokenizer, ElectraForSequenceClassification\r\n",
    "import torch"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#model = ElectraForSequenceClassification.from_pretrained(\"monologg/koelectra-base-v2-discriminator\")\r\n",
    "tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v2-discriminator\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "MAX_LEN = 256"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "연구목표: ~~128~~ 64 + 연구내용:~~256~~ 128 + 기대효과:~~128~~ 64\r\n",
    "\r\n",
    "각각 반으로 줄임. max_len이 256이 되도록,"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "remake dataset to fit on BERT / ELECTRA / etc..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def f1_tokenizer(sent, MAX_LEN):\r\n",
    "    encoded_dict=tokenizer.encode_plus(text = sent, add_special_tokens=True, max_length=MAX_LEN, pad_to_max_length=True, return_attention_mask=True, truncation = True)\r\n",
    "\t\r\n",
    "    input_id=encoded_dict['input_ids']\r\n",
    "    attention_mask=encoded_dict['attention_mask']\r\n",
    "    token_type_id = encoded_dict['token_type_ids']\r\n",
    "    \r\n",
    "    return input_id, attention_mask, token_type_id\r\n",
    "\r\n",
    "def f2_tokenizer(sent, MAX_LEN):\r\n",
    "    encoded_dict=tokenizer.encode_plus(text = sent, add_special_tokens=True, max_length=MAX_LEN+1, pad_to_max_length=True, return_attention_mask=True, truncation = True)\r\n",
    "\t\r\n",
    "    input_id=encoded_dict['input_ids'][1:]                   # 각각 index1부터 슬라이스 한 이유는, [CLS] 토큰을 제거하기 위함.\r\n",
    "    attention_mask=encoded_dict['attention_mask'][1:]        # [CLS] 토큰을 제거하면 MAX_LEN에서 1만큼 줄어들텐데, 최종 길이를 MAX_LEN으로 하기 위해 \r\n",
    "    token_type_id = encoded_dict['token_type_ids'][1:]       # encode_plus(max_length=MAX_LEN+1)\r\n",
    "    \r\n",
    "    return input_id, attention_mask, token_type_id"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "위 코드를 짤때, \r\n",
    "\r\n",
    "# |[CLS] '요약문_연구목표' [SEP] |'요약문_연구내용' [SEP] | '요약문_기대효과' [SEP]|\r\n",
    "# |-----       64       -----|-----       128       -----|-----       64       -----|\r\n",
    "가 되도록."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "input_ids =[]\r\n",
    "attention_masks =[]\r\n",
    "token_type_ids =[]\r\n",
    "\r\n",
    "for train_obj in tqdm(train_data['요약문_연구목표']):\r\n",
    "    input_id1, attention_mask1, token_type_id1 = f1_tokenizer(train_obj, MAX_LEN=64)\r\n",
    "    \r\n",
    "    \r\n",
    "    input_ids.append(input_id1)\r\n",
    "    attention_masks.append(attention_mask1)\r\n",
    "    token_type_ids.append(token_type_id1)\r\n",
    "    \r\n",
    "    \r\n",
    "for i, train_con in tqdm(enumerate(train_data['요약문_연구내용'])):\r\n",
    "    input_id2, attention_mask2, token_type_id2 = f2_tokenizer(train_con, MAX_LEN=128)\r\n",
    "    \r\n",
    "    input_ids[i].extend(input_id2)\r\n",
    "    attention_masks[i].extend(attention_mask2)\r\n",
    "    token_type_ids[i].extend(token_type_id2)\r\n",
    "\r\n",
    "for i, train_exp in tqdm(enumerate(train_data['요약문_기대효과'])):\r\n",
    "    input_id3, attention_mask3, token_type_id3 = f2_tokenizer(train_exp, MAX_LEN=64)\r\n",
    "    \r\n",
    "    input_ids[i].extend(input_id3)\r\n",
    "    attention_masks[i].extend(attention_mask3)\r\n",
    "    token_type_ids[i].extend(token_type_id3)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/174304 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "52355201e82340c9908f6a5476c48c5f"
      }
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "test_input_ids =[]\r\n",
    "test_attention_masks =[]\r\n",
    "test_token_type_ids =[]\r\n",
    "\r\n",
    "for test_obj in tqdm(test_data['요약문_연구목표']):\r\n",
    "    input_id1, attention_mask1, token_type_id1 = f1_tokenizer(test_obj, MAX_LEN=64)\r\n",
    "    \r\n",
    "    \r\n",
    "    test_input_ids.append(input_id1)\r\n",
    "    test_attention_masks.append(attention_mask1)\r\n",
    "    test_token_type_ids.append(token_type_id1)\r\n",
    "    #########################################\r\n",
    "    #train_data_labels.append(train_label)\r\n",
    "    \r\n",
    "for i, test_con in tqdm(enumerate(test_data['요약문_연구내용'])):\r\n",
    "    input_id2, attention_mask2, token_type_id2 = f2_tokenizer(test_con, MAX_LEN=128)\r\n",
    "    \r\n",
    "    test_input_ids[i].extend(input_id2)\r\n",
    "    test_attention_masks[i].extend(attention_mask2)\r\n",
    "    test_token_type_ids[i].extend(token_type_id2)\r\n",
    "\r\n",
    "for i, test_exp in tqdm(enumerate(test_data['요약문_기대효과'])):\r\n",
    "    input_id3, attention_mask3, token_type_id3 = f2_tokenizer(test_exp, MAX_LEN=64)\r\n",
    "    \r\n",
    "    test_input_ids[i].extend(input_id3)\r\n",
    "    test_attention_masks[i].extend(attention_mask3)\r\n",
    "    test_token_type_ids[i].extend(token_type_id3)"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/43576 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "81a0f635c7ad4036bad4350969542160"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ae6e39c8f7a44f5e8e742354d8ad73f0"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "55939d56aa5d48e5b8a3511208e28f5c"
      }
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "train_inputs, valid_inputs, train_labels, valid_labels = train_test_split(input_ids, train_data['label'].values, random_state=42, test_size=0.1)\r\n",
    "train_masks, valid_masks, _, _ = train_test_split(attention_masks, input_ids, random_state=42, test_size=0.1)\r\n",
    "train_token_ids, valid_token_ids, _, _ = train_test_split(token_type_ids, input_ids, random_state=42, test_size=0.1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "train_inputs = torch.tensor(train_inputs)\r\n",
    "train_labels = torch.tensor(train_labels)\r\n",
    "train_masks = torch.tensor(train_masks)\r\n",
    "train_token_ids = torch.tensor(train_token_ids)\r\n",
    "valid_inputs = torch.tensor(valid_inputs)\r\n",
    "valid_labels = torch.tensor(valid_labels)\r\n",
    "valid_masks = torch.tensor(valid_masks)\r\n",
    "valid_token_ids = torch.tensor(valid_token_ids)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "BATCH_SIZE = 16\r\n",
    "\r\n",
    "trainset = TensorDataset(train_inputs, train_masks, train_token_ids, train_labels)\r\n",
    "train_sampler = RandomSampler(trainset)\r\n",
    "train_dataloader = DataLoader(trainset, sampler=train_sampler, batch_size=BATCH_SIZE)\r\n",
    "\r\n",
    "validset = TensorDataset(valid_inputs, valid_masks, valid_token_ids, valid_labels)\r\n",
    "valid_sampler = SequentialSampler(validset)\r\n",
    "valid_dataloader = DataLoader(validset, sampler=valid_sampler, batch_size=BATCH_SIZE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "test_inputs = torch.tensor(test_input_ids)\r\n",
    "# test_labels = torch.tensor(test_data['label'])     test는 non label\r\n",
    "test_masks = torch.tensor(test_attention_masks)\r\n",
    "test_token_ids = torch.tensor(test_token_type_ids)\r\n",
    "\r\n",
    "testset = TensorDataset(test_inputs, test_masks, test_token_ids)\r\n",
    "test_sampler = RandomSampler(testset)\r\n",
    "test_dataloader = DataLoader(testset, sampler=test_sampler, batch_size=BATCH_SIZE)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "device = torch.device(\"cuda:0\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "model = ElectraForSequenceClassification.from_pretrained(\"monologg/koelectra-base-v2-discriminator\", num_labels=46)\r\n",
    "model.to(device)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at monologg/koelectra-base-v2-discriminator were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v2-discriminator and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(32200, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=46, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8) # 0으로 나누는 것을 방지하기 위한 epsilon 값\r\n",
    "epochs = 10\r\n",
    "# 총 훈련 스텝\r\n",
    "total_steps = len(train_dataloader) * epochs\r\n",
    "# lr 조금씩 감소시키는 스케줄러\r\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "# 정확도 계산 함수\r\n",
    "def flat_accuracy(preds, labels):\r\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\r\n",
    "    labels_flat = labels.flatten()\r\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\r\n",
    "\r\n",
    "# 시간 표시 함수\r\n",
    "def format_time(elapsed):\r\n",
    "    # 반올림\r\n",
    "    elapsed_rounded = int(round((elapsed)))\r\n",
    "    # hh:mm:ss으로 형태 변경\r\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "# 재현을 위해 랜덤시드 고정\r\n",
    "seed_val = 42\r\n",
    "random.seed(seed_val)\r\n",
    "np.random.seed(seed_val)\r\n",
    "torch.manual_seed(seed_val)\r\n",
    "torch.cuda.manual_seed_all(seed_val)\r\n",
    "\r\n",
    "# 그래디언트 초기화\r\n",
    "model.zero_grad()\r\n",
    "\r\n",
    "# 에폭만큼 반복\r\n",
    "for epoch_i in range(0, epochs):\r\n",
    "    \r\n",
    "    # ========================================\r\n",
    "    #               Training\r\n",
    "    # ========================================\r\n",
    "    \r\n",
    "    print(\"\")\r\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\r\n",
    "    print('Training...')\r\n",
    "\r\n",
    "    # 시작 시간 설정\r\n",
    "    t0 = time.time()\r\n",
    "\r\n",
    "    # 로스 초기화\r\n",
    "    total_loss = 0\r\n",
    "    \r\n",
    "\r\n",
    "    # 훈련모드로 변경\r\n",
    "    model.train()\r\n",
    "        \r\n",
    "    # 데이터로더에서 배치만큼 반복하여 가져옴\r\n",
    "    for step, batch in enumerate(train_dataloader):\r\n",
    "        # 경과 정보 표시\r\n",
    "        if step % 1000 == 0 and not step == 0:\r\n",
    "            elapsed = format_time(time.time() - t0)\r\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\r\n",
    "\r\n",
    "        # 배치를 GPU에 넣음\r\n",
    "        batch = tuple(t.to(device) for t in batch)\r\n",
    "        \r\n",
    "        # 배치에서 데이터 추출\r\n",
    "        b_input_ids, b_input_mask, b_token_ids, b_labels = batch\r\n",
    "\r\n",
    "        # Forward 수행                \r\n",
    "        outputs = model(b_input_ids, token_type_ids=b_token_ids, attention_mask=b_input_mask, labels=b_labels)\r\n",
    "        \r\n",
    "        # 로스 구함\r\n",
    "        loss = outputs[0]\r\n",
    "\r\n",
    "        # 총 로스 계산\r\n",
    "        total_loss += loss.item()\r\n",
    "\r\n",
    "        # Backward 수행으로 그래디언트 계산\r\n",
    "        loss.backward()\r\n",
    "\r\n",
    "        # 그래디언트 클리핑\r\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\r\n",
    "\r\n",
    "        # 그래디언트를 통해 가중치 파라미터 업데이트\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        # 스케줄러로 학습률 감소\r\n",
    "        scheduler.step()\r\n",
    "\r\n",
    "        # 그래디언트 초기화\r\n",
    "        model.zero_grad()\r\n",
    "\r\n",
    "    # 평균 로스 계산\r\n",
    "    avg_train_loss = total_loss / len(train_dataloader)            \r\n",
    "\r\n",
    "    print(\"\")\r\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\r\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\r\n",
    "        \r\n",
    "    # ========================================\r\n",
    "    #               Validation\r\n",
    "    # ========================================\r\n",
    "\r\n",
    "    print(\"\")\r\n",
    "    print(\"Running Validation...\")\r\n",
    "\r\n",
    "    #시작 시간 설정\r\n",
    "    t0 = time.time()\r\n",
    "\r\n",
    "    # 평가모드로 변경\r\n",
    "    model.eval()\r\n",
    "\r\n",
    "    # 변수 초기화\r\n",
    "    valid_loss, valid_accuracy = 0, 0\r\n",
    "    nb_valid_steps, nb_valid_examples = 0, 0\r\n",
    "\r\n",
    "    # 데이터로더에서 배치만큼 반복하여 가져옴\r\n",
    "    for batch in valid_dataloader:\r\n",
    "        # 배치를 GPU에 넣음\r\n",
    "        batch = tuple(t.to(device) for t in batch)\r\n",
    "        \r\n",
    "        # 배치에서 데이터 추출\r\n",
    "        b_input_ids, b_input_mask, b_token_ids, b_labels = batch\r\n",
    "        \r\n",
    "        # 그래디언트 계산 안함\r\n",
    "        with torch.no_grad():     \r\n",
    "            # Forward 수행\r\n",
    "            outputs = model(b_input_ids, token_type_ids=b_token_ids, attention_mask=b_input_mask, labels=b_labels)\r\n",
    "        \r\n",
    "        # 로스 구함\r\n",
    "        logits = outputs[0]\r\n",
    "\r\n",
    "        valid_loss += logits.item()\r\n",
    "\r\n",
    "        # CPU로 데이터 이동\r\n",
    "        logits = logits.detach().cpu().numpy()\r\n",
    "        label_ids = b_labels.to('cpu').numpy()\r\n",
    "        \r\n",
    "        # 출력 로짓과 라벨을 비교하여 정확도 계산\r\n",
    "        tmp_valid_accuracy = flat_accuracy(logits, label_ids)\r\n",
    "        valid_accuracy += tmp_valid_accuracy\r\n",
    "        nb_valid_steps += 1\r\n",
    "    \r\n",
    "    avg_valid_loss = valid_loss / len(valid_dataloader)            \r\n",
    "    print(\"  Accuracy: {0:.2f}\".format(valid_accuracy/nb_valid_steps))    \r\n",
    "    print(\"  Average validation loss: {0:.2f}\".format(avg_valid_loss))\r\n",
    "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\r\n",
    "\r\n",
    "print(\"\")\r\n",
    "print(\"Training complete!\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "======== Epoch 1 / 10 ========\n",
      "Training...\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 192.00 MiB (GPU 6; 10.76 GiB total capacity; 9.55 GiB already allocated; 42.56 MiB free; 9.61 GiB reserved in total by PyTorch)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_30319/842834027.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# Forward 수행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         outputs = model(b_input_ids, \n\u001b[0m\u001b[1;32m     46\u001b[0m                         \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_token_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                         \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mb_input_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kobert/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kobert/lib/python3.8/site-packages/transformers/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0mheads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \"\"\"\n\u001b[0;32m--> 412\u001b[0;31m         discriminator_hidden_states = self.electra(\n\u001b[0m\u001b[1;32m    413\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kobert/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kobert/lib/python3.8/site-packages/transformers/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_project\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         hidden_states = self.encoder(\n\u001b[0m\u001b[1;32m    330\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kobert/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kobert/lib/python3.8/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 )\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    434\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kobert/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kobert/lib/python3.8/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m     ):\n\u001b[0;32m--> 370\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    371\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/kobert/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kobert/lib/python3.8/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     ):\n\u001b[0;32m--> 314\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/envs/kobert/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/kobert/lib/python3.8/site-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 6; 10.76 GiB total capacity; 9.55 GiB already allocated; 42.56 MiB free; 9.61 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#시작 시간 설정\r\n",
    "t0 = time.time()\r\n",
    "\r\n",
    "# 평가모드로 변경\r\n",
    "model.eval()\r\n",
    "\r\n",
    "# 변수 초기화\r\n",
    "test_loss, test_accuracy = 0, 0\r\n",
    "nb_test_steps, nb_test_examples = 0, 0\r\n",
    "y_pred_list = []\r\n",
    "\r\n",
    "# 데이터로더에서 배치만큼 반복하여 가져옴\r\n",
    "for step, batch in enumerate(test_dataloader):\r\n",
    "    # 경과 정보 표시\r\n",
    "    if step % 100 == 0 and not step == 0:\r\n",
    "        elapsed = format_time(time.time() - t0)\r\n",
    "        print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(test_dataloader), elapsed))\r\n",
    "\r\n",
    "    # 배치를 GPU에 넣음\r\n",
    "    batch = tuple(t.to(device) for t in batch)\r\n",
    "    \r\n",
    "    # 배치에서 데이터 추출\r\n",
    "    b_input_ids, b_input_mask, b_token_ids = batch\r\n",
    "\r\n",
    "    # 그래디언트 계산 안함\r\n",
    "    with torch.no_grad():     \r\n",
    "        # Forward 수행\r\n",
    "        outputs = model(b_input_ids, \r\n",
    "                        token_type_ids=None, \r\n",
    "                        attention_mask=b_input_mask)\r\n",
    "    y_pred_list.append(outputs)\r\n",
    "    # 로스 구함\r\n",
    "    logits = outputs[0]\r\n",
    "\r\n",
    "    # CPU로 데이터 이동\r\n",
    "    logits = logits.detach().cpu().numpy()\r\n",
    "    label_ids = b_labels.to('cpu').numpy()\r\n",
    "    \r\n",
    "    # 출력 로짓과 라벨을 비교하여 정확도 계산\r\n",
    "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\r\n",
    "    eval_accuracy += tmp_eval_accuracy\r\n",
    "    nb_eval_steps += 1\r\n",
    "\r\n",
    "print(\"\")\r\n",
    "print(\"Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\r\n",
    "print(\"Test took: {:}\".format(format_time(time.time() - t0)))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('kobert': conda)"
  },
  "interpreter": {
   "hash": "2edddfc9d5bed511733511e71708c2823425ae529162a5f8877df66aaf5564aa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}